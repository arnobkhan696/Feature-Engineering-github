{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "33nTE-9zKJ1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions\n",
        "\n",
        "1. What is a parameter?\n",
        "  - A parameter in Python is a named entity specified in a function definition that acts as a placeholder for a value that will be passed to the function when it is called. It allows functions to accept input and operate on it, making them more versatile and reusable.\n",
        "2. What is correlation? What does negative correlation mean?\n",
        "  - Correlation describes the relationship between two or more variables. When variables change in the same direction (one increases, the other increases, or one decreases, the other decreases), it's called a positive correlation. When variables change in opposite directions (one increases, the other decreases), it's a negative correlation.\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - The main components in machine learning include data, algorithms, models, and predictions.\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "  - Loss value provides a numerical measure of how well a machine learning model is performing. A lower loss value generally indicates that the model's predictions are closer to the actual values, suggesting better performance. Conversely, a higher loss value suggests that the model is making larger errors and is therefore performing poorly.\n",
        "5. What are continuous and categorical variables?\n",
        "  - In statistics, continuous variables represent numerical values that can take any value within a specified range, while categorical variables represent non-numerical data grouped into categories or groups.\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Handling categorical variables is a fundamental step in preprocessing data for machine learning models, especially those that canâ€™t work directly with non-numerical data. Categorical variables represent types or categories, such as \"color\" or \"country,\" and must be encoded into numerical formats before feeding into algorithms.\n",
        "7. What do you mean by training and testing a dataset?\n",
        "  - In the context of machine learning, training a dataset means using a portion of the data to teach a model how to make predictions or decisions.\n",
        "8. What is sklearn.preprocessing?\n",
        "  - sklearn.preprocessing is a module in the scikit-learn library in Python that provides functions and classes to preprocess data before training machine learning models.\n",
        "9. What is a Test set?\n",
        "  - A test set is a subset of data, separate from the training set, used to evaluate how well a model performs on unseen data after it has been trained.\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "   - In Python, data is typically split into training and testing sets using the train_test_split function from the sklearn.model_selection module. This function randomly divides the data into two subsets: one for training the machine learning model, and another for evaluating its performance on unseen data.\n",
        "   - first, clearly define the problem and its goal, then gather and prepare the necessary data, choose an appropriate machine learning model, train the model, evaluate its performance, and finally, iterate and refine the model based on the evaluation results.\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "   - It allows you to identify data quality issues, like missing values, outliers, and inconsistencies.\n",
        "12. What is correlation?\n",
        "   - correlation refers to a statistical measure that quantifies the strength and direction of the relationship between two or more variables.\n",
        "13. What does negative correlation mean?\n",
        "   - A negative correlation is a relationship between two variables that move in opposite directions.\n",
        "14. How can you find correlation between variables in Python?\n",
        "   - To find the correlation between variables in Python, several methods can be employed using libraries like NumPy, pandas, SciPy, and Seaborn. These methods help quantify and visualize the relationships between variables, aiding in data analysis and interpretation.\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "   - Causation refers to a relationship between two variables where one variable directly affects or brings about a change in the other. In simple terms, if A causes B, then a change in A will produce a change in B.\n",
        "   - Where correlation is A statistical association between two variables, while causation is A direct cause-effect relationship.\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   - an optimizer is an algorithm that adjusts a model's parameters (like weights and biases) to minimize the loss function during training.\n",
        "   - Optimizers can be broadly divided into two categories: i) First-Order Optimizers:- These use only the first derivative (gradient) of the loss function. ii) Advanced Gradient-Based Optimizers:- These improve upon plain gradient descent by adapting learning rates or using momentum.\n",
        "17. What is sklearn.linear_model?\n",
        "   - sklearn.linear_model is a module in the scikit-learn library that implements various linear models for regression and classification tasks. Linear models predict a target variable as a linear combination of input features.\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "   - In machine learning frameworks like Keras (TensorFlow) and Scikit-learn, the model.fit() function is used to train the model on a given dataset.\n",
        "\n",
        "     In simple terms, model.fit():\n",
        "\n",
        "     Adjusts the model's internal parameters (weights and biases) using the input data and labels, to minimize the loss function over multiple iterations (epochs).\n",
        "    - The required arguments must be Keras (TensorFlow) and Scikit-learn, the fit() function\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "   - model.predict() is used in machine learning and deep learning to:\n",
        "     Generate output predictions (inference) from a trained model based on new input data.It is not used during training, but rather after the model is trained, to make predictions on:\n",
        "     test data,\n",
        "     unseen data,\n",
        "     or real-world input\n",
        "    - The argument must be model.predict(x)\n",
        "20. What are continuous and categorical variables?\n",
        "   - continuous variables represent numerical values that can take any value within a specified range, while categorical variables represent non-numerical data grouped into categories or groups.\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "   - Feature scaling is a data preprocessing technique used to normalize or standardize the range of independent variables (features) in a dataset.\n",
        "   - it can help meny way like:\n",
        "     i) Ensures Equal Contribution of Features, ii) Improves Convergence Speed in Gradient Descent, iii) Essential for Distance-Based Algorithms, iv) Helps in Principal Component Analysis (PCA)\n",
        "22. How do we perform scaling in Python?\n",
        "   - Data scaling in Python involves transforming numerical features to a similar scale. This is crucial for algorithms sensitive to feature magnitude, such as distance-based methods (e.g., k-NN, k-means) and gradient-based optimization (e.g., linear regression, neural networks). Common scaling techniques can be implemented using the scikit-learn library.\n",
        "23. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a module in the scikit-learn library that provides functions and classes to transform raw data into a more suitable format for machine learning algorithms. It encompasses various techniques for data scaling, normalization, encoding, and feature engineering. Preprocessing is a crucial step in the machine learning workflow, as it can significantly impact the performance and accuracy of models.\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "   - In Python, data is typically split into training and testing sets using the train_test_split function from the sklearn.model_selection module. This function randomly divides the data into two subsets, with the training set used to train the model and the testing set used to evaluate its performance.\n",
        "25. Explain data encoding?\n",
        "   - Data encoding refers to the process of converting data from one format to another, typically to a numerical representation that machine learning algorithms can understand and process."
      ],
      "metadata": {
        "id": "vbqPQrqBKRQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9JLL9r4JOmm"
      },
      "outputs": [],
      "source": []
    }
  ]
}